[project]
name = "gemma3-qa-finetuning"
version = "0.1.0"
description = "Full FT vs LoRA vs Freezing for extractive QA (SQuAD) with Gemma 3."
readme = "README.md"
requires-python = "==3.12.*"
dependencies = [
    "datasets>=4.4.1",
    "evaluate>=0.4.6",
    "peft>=0.18.0",
    "torch>=2.9.1",
    "transformers>=4.57.1",
]

[build-system]
requires = ["setuptools>=68"]
build-backend = "setuptools.build_meta"

[[tool.uv.index]]
name = "pytorch-cu130"
url = "https://download.pytorch.org/whl/cu130"
explicit = true

[tool.uv.sources]
torch = [
  { index = "pytorch-cu130" },
]

[tool.setuptools.packages.find]
where = ["src"]

[project.scripts]
gemmaqa-train = "gemmaqa.train:main"
gemmaqa-eval  = "gemmaqa.eval:main"
